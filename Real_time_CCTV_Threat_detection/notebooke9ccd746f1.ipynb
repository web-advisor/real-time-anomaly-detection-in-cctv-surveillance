{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport tensorflow as tf\nimport pandas as pd\nimport numpy as np\nimport imageio\nimport cv2\nimport os","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow import keras\nfrom keras.utils.vis_utils import plot_model","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"DATASET_FOLDER = \"../input/real-time-anomaly-detection-in-cctv-surveillance/data\"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset = os.listdir(DATASET_FOLDER)\nlabel_types = os.listdir(DATASET_FOLDER)\nprint(\"Class Labels for Videos : \")\nlabel_types.remove('test.csv')\nlabel_types.remove('train.csv')\nprint(label_types)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Dataset Analysis","metadata":{}},{"cell_type":"code","source":"video_counts = []\ntotal = 0\nfor i in range(len(label_types)):\n    videos = len(os.listdir(os.path.join(DATASET_FOLDER, label_types[i])))\n    video_counts.append(videos)\n    total += videos\n\nprint(f\"Total videos : {total}\")\nprint(label_types)\nprint(video_counts)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(15,5))\nplt.bar(label_types, video_counts, width=0.4, align=\"center\" )\nplt.xticks(rotation=90)\n\nplt.xlabel(\"Classes of Videos\")\nplt.ylabel(\"Number of Videos\")\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(15,10))\nplt.pie(x=np.array(video_counts), autopct=\"%.1f%%\", labels=label_types, pctdistance=0.5)\nplt.title(\"Share of Different Types Of Training Videos\", fontsize=14)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Train and Test Split:","metadata":{}},{"cell_type":"code","source":"LABEL_COL = \"label\"\nVIDEO_INFO_COL = \"video_name\"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data = []\n\nfor i in range(len(label_types)):\n    for video in os.listdir(os.path.join(DATASET_FOLDER, label_types[i])): \n        data.append( (label_types[i] , f\"../input/real-time-anomaly-detection-in-cctv-surveillance/data/{label_types[i]}/{video}\") )\n\ndf = pd.DataFrame(data=data, columns=[ LABEL_COL, VIDEO_INFO_COL])\n\nprint(df)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x = df[VIDEO_INFO_COL]\ny = df[LABEL_COL]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train, test = train_test_split(df, test_size = 0.2, stratify=y)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.value_counts(LABEL_COL)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test.value_counts(LABEL_COL)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(15, 10))\nplt.pie(x=np.array([len(train), len(test)]), autopct=\"%.1f%%\", explode=[0.03, 0.03], labels=[\"Training Data\", \"Test Data\"], pctdistance=0.5)\nplt.title(\"Share of Training and Testing Videos\", fontsize=14)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.to_csv(\"../working/train.csv\")\ntest.to_csv(\"../working/test.csv\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Data Collection :","metadata":{}},{"cell_type":"code","source":"train_df = pd.read_csv(\"../working/train.csv\")\ntest_df = pd.read_csv(\"../working/test.csv\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f\"Total videos for training : {len(train_df)}\")\nprint(f\"Total videos for testing  : {len(test_df)}\")\n\nprint(\"Training Dataframe : \")\nprint(train_df.head(10))\n\nprint(\"Testing Dataset    : \")\nprint(test_df.head(10))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Feed the videos to a Network : ","metadata":{}},{"cell_type":"code","source":"IMG_SIZE = 299\n\ndef crop_center_square(frame):\n    y, x = frame.shape[0:2]\n    min_dim = min(y,x)\n    # print(f\"y : {y}      and      x : {x}\")\n    start_x = (x // 2) -  (min_dim // 2) \n    start_y = (y // 2) -  (min_dim // 2)\n    return frame[ start_y : start_y+min_dim, start_x : start_x + min_dim]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def load_video(path, max_frames = 0, resize = (IMG_SIZE, IMG_SIZE)):\n\n    cap = cv2.VideoCapture(path)\n    # allPaths = path.split('/')\n    # videoNameAndExt = allPaths[2].split('.')\n    # videoName = videoNameAndExt[0] \n    frames = []\n    # i = 0\n    try:\n        while True:\n            ret, frame = cap.read()\n            if not ret:\n                break\n            # if (not os.path.exists('frames/'+videoName)):\n            #     os.mkdir('frames/'+videoName)\n            frame = crop_center_square(frame)\n            frame = cv2.resize(frame, resize)\n            frame = frame[:, :, [2,1,0]]\n            # cv2.imwrite('frames/'+ videoName +'/Frame'+ str(i) +'.jpg', frame)\n            frames.append(frame)\n            # i+=1\n            if(len(frames) == max_frames):\n                break\n    finally:\n        cap.release()\n    return np.array(frames)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def build_feature_extractor():\n    feature_extractor = keras.applications.InceptionV3(\n        weights=\"imagenet\",\n        include_top=False,\n        pooling=\"avg\",\n        input_shape=(IMG_SIZE, IMG_SIZE, 3),\n    )\n    preprocess_input = keras.applications.inception_v3.preprocess_input\n\n    inputs = keras.Input((IMG_SIZE, IMG_SIZE, 3))\n    preprocessed = preprocess_input(inputs)\n\n    outputs = feature_extractor(preprocessed)\n    return keras.Model(inputs, outputs, name=\"feature_extractor\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"feature_extractor = build_feature_extractor()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(feature_extractor.summary())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Label Encoding\nStringLookup layer encode the class labels as integers.","metadata":{}},{"cell_type":"code","source":"label_processor = keras.layers.StringLookup(num_oov_indices=0, vocabulary=np.unique(train_df[\"label\"]))\nprint(label_processor.get_vocabulary())\n\nlabels = train_df[\"label\"].values\nlabels = label_processor(labels[..., None]).numpy()\nlabels","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<b>Finally, we can put all the pieces together to create our data processing utility.</b>","metadata":{}},{"cell_type":"code","source":"#Define hyperparameters\n\nIMG_SIZE = 299\nBATCH_SIZE = 64\nEPOCHS = 30\n\nMAX_SEQ_LENGTH = 20\nNUM_FEATURES = 2048","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def prepare_all_videos(df):\n    num_samples = len(df)\n    video_paths = df[\"video_name\"].values.tolist()    \n    \n    ##take all classlabels from train_df column named 'label' and store in labels\n    labels = df[\"label\"].values\n\n    #convert classlabels to label encoding\n    labels = label_processor(labels[..., None]).numpy()\n\n    # `frame_masks` and `frame_features` are what we will feed to our sequence model.\n    # `frame_masks` will contain a bunch of booleans denoting if a timestep is\n    # masked with padding or not.\n    frame_masks = np.zeros(shape=(num_samples, MAX_SEQ_LENGTH), dtype=\"bool\") \n    frame_features = np.zeros(shape=(num_samples, MAX_SEQ_LENGTH, NUM_FEATURES), dtype=\"float32\") \n\n    # For each video.\n    for idx, path in enumerate(video_paths):\n        # Gather all its frames and add a batch dimension.\n        print(f\"Processing video {idx} out of {num_samples}\")\n        \n        frames = load_video(path)\n        frames = frames[None, ...]\n        # Initialize placeholders to store the masks and features of the current video.\n        temp_frame_mask = np.zeros(shape=(1, MAX_SEQ_LENGTH,), dtype=\"bool\")\n        temp_frame_features = np.zeros(\n            shape=(1, MAX_SEQ_LENGTH, NUM_FEATURES), dtype=\"float32\"\n        )\n\n        # Extract features from the frames of the current video.\n        for i, batch in enumerate(frames):\n            print(f\"\\tProcessing frame {i} out of {len(frames)}\")\n            video_length = batch.shape[0]\n            length = min(MAX_SEQ_LENGTH, video_length)\n            for j in range(length):\n                temp_frame_features[i, j, :] = feature_extractor.predict(\n                    batch[None, j, :]\n                )\n            temp_frame_mask[i, :length] = 1  # 1 = not masked, 0 = masked\n\n        frame_features[idx,] = temp_frame_features.squeeze()\n        frame_masks[idx,] = temp_frame_mask.squeeze()\n\n    return (frame_features, frame_masks), labels","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data, train_labels = prepare_all_videos(train_df)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}